---
layout: post
title: 关于项目的进展
---

Date: 09-22 2020 23:00 Tuesday

打字的时候总是感觉思路受阻，这就是思考不彻底的原因吧
我还是比较偷懒的，懒惰了这么久，整个项目从立项开始都已经过了一年了，才推进了这么一点，真的很拉跨。

###### 言归正传，目前取得进度是：
1.基于Selenium完成了OTRS数据的爬取；
2.基于朴素贝叶斯完成了文本翻译，矢量化以及简单的识别；
3.基于Selenium复现了一部分OTRS的操作，包括Owner及简单的Reply；
  
这进度简直可怕，实际上在3月初就已经完成了以上这些功能中的部分。这是值得反思的一个问题。

###### 再来看看还未完成的功能：
1. 基于Mysql数据库的建立及数据对接；
2. 基于ECharts的数据分析和数据可视化部分；
3. 消息队列服务起的搭建；
4. 微信小程序实验。

以上可以说是大的功能模块，最重要的还是在于系统的引擎部分，也就是整体的核心：文本分类
文本分类的方法有很多，基于传统机器学习的：KNN、Naive Bayes、SVM等等都是可取的，而目前代码中所使用的核心算法即使多分类朴素贝叶斯
我并没有比较过SVM和Bayes的实际效果，因为SVM要求对数据重新处理，并且提供相关的特征。这对于Bayes而言，工作量实在是很大，而且就算有提升，效果仍然十分微小。
目前在Bayes中训练集能够达到95%左右的准确率，但是在实际运行中，仍然发生了很多误判的情况。
究其根本，Bayes的原理是通过已知的概率去求得未知的概率，在一个短句文本中，剔除掉那些无关的单词之后，产生的就是所谓的 <b><em>Word-List</em></b>，那么在这个list中的每个单词都会有一个对应的概率，也就是在当前分类下，出现该单词的概率，然后通过Bayes公式计算出出现当前单词时，在当前分类下的概率。
Bayes需要假设每个特征单词时互相独立的，也就是上一个单词出现并不会影响下一个单词出现的概率，但是实际情况中短句文本间的单词或多或少存在这一些关联，例如语法和固定词组等关系，这些关系是否会对最后的正确率产生影响，我还没有进行实验。
另一方面文本的一大特点就是具有时间序列，时间序列实际也是每个单词之间的一个关系，所以Bayes仅仅只能用来处理分类，并不能真正很好的分析和学习语义。也就是说，将一句话中所有单词的顺序全部打乱，Bayes仍能得到正确的分类，但是在人类的视角，这句话是不存在任何意义的。
我并没有接触过目前非常流行的Bert模型，NLP中我接触的较多的可能也只有RNN和LSTM了，但这两种模型都对样本量有要求，并且其实从分类的角度上来讲，分类效果并不如Bayes来的更好。

###### 那么目前针对模型方面，我的问题在于：
  1.是否要继续选择Bayes作为我的分类模型？
  2.对于模型的优化，目前存在的就是正确率以及非均衡样本学习的方向？
  3.如果挑选其他模型，是否有可以提升的空间，是否考虑使用神经网络来解决问题？
  4.当前数据的清理工作应该如何进行？
  5.文本转化为向量时，是否存在其他的转化方式？
  
语义的学习，必然能够增加文本分类的正确率，或者换句话说，是否能够模仿人类的判断行为，时非常重要的。
然而从学习到判断，整个流程太长，并且模仿人类的学习机制，首先先要清楚人类如何理解文字、词组和句子；还要通过语境进行判断，这工作量及需要学习补充的内容属实超过了我目前可支配的时间。
不过换句话说，如果我真的研究出来，那也称得上是NLP界的大佬了，哈哈哈哈哈！
总之，目前最重要的是将各功能模块完成后，再考虑算法的问题。
当然，一些情况下的记录也是必要的。
希望能够顺利完成这个项目！
